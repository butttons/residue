# residue

An open-source CLI + self-hosted backend that captures AI agent conversations and links them to git commits. Every push uploads the conversations that informed your code changes, creating a searchable record of how code was written.

## How It Works

There are two event sources: **agent adapters** and **git hooks**.

Agent adapters call into the CLI when conversations start and end. Git hooks call into the CLI when commits and pushes happen. The CLI maintains local state that connects the two.

```
Agent Adapter                   Git Hooks
    |                               |
    |-- session-start --\           |
    |                    v          |
    |              LOCAL STATE      |
    |              (pending queue)  |
    |-- session-end ----/           |
    |                               |-- post-commit -> capture
    |                               |   (tag pending sessions with SHA)
    |                               |
    |                               |-- pre-push -> sync
    |                               |   (upload to worker, clear local state)
```

1. Adapter calls `residue session start` when a conversation begins
2. User works with the AI agent, making code changes
3. Adapter calls `residue session end` when the conversation ends
4. User commits -- `post-commit` hook tags all pending sessions with the commit SHA
5. User pushes -- `pre-push` hook uploads session data + commit mappings to the worker

A single conversation can span multiple commits. The full session is stored once and multiple commits reference it.

## Architecture

```
packages/
  cli/              -> "@residue/cli" npm package
  worker/           -> Cloudflare Worker (Hono + JSX)
```

Monorepo managed with pnpm workspaces. Runtime is bun.

## Prerequisites

- [bun](https://bun.sh) -- runtime for the CLI
- A [Cloudflare](https://dash.cloudflare.com) account

## Setup

There are four steps: create the R2 bucket and its S3 API credentials, deploy the worker, install the CLI, then configure your repos.

### Step 1: Create the R2 bucket and S3 API credentials

The CLI uploads session data directly to R2 via presigned URLs. This requires an R2 bucket and S3 API credentials. You must set these up before deploying the worker.

1. Go to the [Cloudflare dashboard](https://dash.cloudflare.com)
2. Navigate to **R2 Object Storage** in the sidebar
3. Click **Create bucket**, name it `residue` (or whatever you prefer), and create it
4. Go to **R2 Object Storage > API Tokens** (in the R2 sidebar, not the main API tokens page)
5. Click **Create API Token**
6. Give it **Object Read & Write** permissions, scoped to the bucket you just created
7. Save the following values -- you will need them in Step 2:
   - **Access Key ID**
   - **Secret Access Key**
   - **Account ID** (visible in the Cloudflare dashboard URL or the R2 overview page)
   - **Bucket name** (whatever you named it in step 3)

### Step 2: Deploy the worker

The worker stores commit metadata in D1 and serves the browsable UI. Session data lives in R2 (set up in Step 1).

```bash
cd packages/worker
```

**Option A: Automated setup**

```bash
bash setup.sh
```

The script creates a D1 database, runs migrations, generates an auth token, and deploys. After it finishes, you still need to set the R2 credentials as secrets:

```bash
wrangler secret put R2_SECRET_ACCESS_KEY
# Paste the secret access key from Step 1 when prompted
```

Then update `wrangler.jsonc` with your R2 values:

```jsonc
{
  "vars": {
    "R2_ACCESS_KEY_ID": "<your access key id>",
    "R2_ACCOUNT_ID": "<your account id>",
    "R2_BUCKET_NAME": "<your bucket name>"
  }
}
```

Redeploy to pick up the changes:

```bash
wrangler deploy
```

**Option B: Manual setup**

```bash
# Create D1 database
wrangler d1 create residue-db
# Copy the database_id into wrangler.jsonc

# Run migrations
wrangler d1 execute residue-db --remote --file=migrations/0001_init.sql

# Create R2 bucket (skip if done in Step 1 via the dashboard)
wrangler r2 bucket create residue

# Set secrets
echo "your-secret-token" | wrangler secret put AUTH_TOKEN
wrangler secret put ADMIN_PASSWORD   # password for the web UI
wrangler secret put R2_SECRET_ACCESS_KEY   # from Step 1

# Update wrangler.jsonc with your values:
#   - d1_databases[0].database_id  -> your D1 database ID
#   - R2_ACCESS_KEY_ID             -> from Step 1
#   - R2_ACCOUNT_ID                -> from Step 1
#   - R2_BUCKET_NAME               -> from Step 1
#   - ADMIN_USERNAME               -> username for the web UI
#   - r2_buckets[0].bucket_name    -> your bucket name

# Deploy
wrangler deploy
```

At the end of either option you should have:
- A **worker URL** (e.g. `https://residue.your-subdomain.workers.dev`)
- An **auth token** (generated by the setup script, or the one you set manually)

### Step 3: Install the CLI

```bash
bun add -g @residue/cli
```

### Step 4: Configure a repository

Run these commands inside the git repo you want to track:

```bash
# Save your worker URL and token (one-time, stored in ~/.residue/config)
residue login --url https://your-worker.workers.dev --token YOUR_TOKEN

# Install git hooks (post-commit + pre-push)
residue init

# Set up an agent adapter (pick one)
residue setup claude-code    # for Claude Code
residue setup pi             # for pi coding agent
```

**What `residue init` does:** Installs a `post-commit` hook that runs `residue capture` (tags pending sessions with the commit SHA) and a `pre-push` hook that runs `residue sync` (uploads everything to your worker). It also adds `.residue/` to `.gitignore`.

**What `residue setup` does:**
- `claude-code` -- Adds `SessionStart` and `SessionEnd` hooks to `.claude/settings.json` that call `residue hook claude-code`
- `pi` -- Installs a pi extension at `.pi/extensions/residue.ts` that calls `residue session start` and `residue session end`

After this, conversations are captured automatically. Commit and push as you normally would.

## CLI Commands

| Command | Description |
|---|---|
| `residue login` | Save worker URL + auth token to `~/.residue/config` |
| `residue init` | Install git hooks in current repo |
| `residue setup <agent>` | Configure an agent adapter (`claude-code` or `pi`) |
| `residue push` | Manually upload pending sessions |
| `residue capture` | Tag pending sessions with current commit SHA (called by post-commit hook) |
| `residue sync` | Upload sessions to worker (called by pre-push hook) |
| `residue session start` | Register a new session (called by adapters) |
| `residue session end` | Mark a session as ended (called by adapters) |

## Worker

The worker serves both a JSON API and a server-rendered UI.

**API routes** (bearer token auth):

| Route | Description |
|---|---|
| `POST /api/sessions/upload-url` | Generate a presigned R2 PUT URL for direct upload |
| `POST /api/sessions` | Upload session metadata + commit mappings |
| `GET /api/sessions/:id` | Fetch raw session data |
| `GET /api/repos/:org/:repo` | List commits with linked sessions |
| `GET /api/repos/:org/:repo/:sha` | Get sessions for a specific commit |

**UI routes** (basic auth, served under `/app`):

| Route | Description |
|---|---|
| `/app` | List of orgs |
| `/app/:org` | List of repos in org |
| `/app/:org/:repo` | Commit timeline with linked sessions |
| `/app/:org/:repo/:sha` | Commit permalink with full conversation |

Org and repo are inferred from the git remote URL. No manual configuration needed.

## Development

```bash
# Install dependencies
pnpm install

# Start the worker dev server
pnpm run dev:worker

# Build the CLI
pnpm run build:cli

# Run tests
pnpm --filter @residue/cli test      # CLI tests
pnpm --filter @residue/worker test       # worker tests
```

## Design Decisions

- **No data normalization.** Raw agent session data is stored as-is in R2. The UI uses mappers to transform each agent's format into a common message format for rendering.
- **Direct R2 upload.** Session data is uploaded directly to R2 via presigned PUT URLs, bypassing the worker's request body size limits. The worker only handles lightweight metadata.
- **Self-hosted.** Each user/team deploys their own Cloudflare Worker. No multi-tenant backend, no data privacy concerns.
- **Single auth token.** Set at deploy time as an environment variable. No user management.
- **Never block git.** Hooks exit 0 even on errors. Session capture and sync are best-effort.

## License

MIT
